"""LangGraph-based AI orchestrator with Claude (Anthropic).

Implements a ReAct agent that:
- Parses Korean economic queries
- Calls FRED data tools
- Provides Korean analysis with Korean market implications
- Maintains session-based conversation memory
"""

from __future__ import annotations

import asyncio
import json as _json
import re
import uuid
from typing import Annotated, Any

from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_core.tools import tool
from langchain_anthropic import ChatAnthropic
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from pydantic import BaseModel, Field

from app.config import get_settings
from app.models import (
    ChatMessage,
    ChatResponse,
    ContentType,
    FredSeriesData,
    FredSeriesInfo,
    MessageRole,
)
from app.services.fred_service import fred_service
from app.data.indicators import MAJOR_INDICATORS
from app.data.translations import FRED_TITLES_KO


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  System Prompt
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SYSTEM_PROMPT_KO = """ë‹¹ì‹ ì€ FRED-OS ê²½ì œ ë°ì´í„° ë¶„ì„ í„°ë¯¸ë„ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—­í• ì€ ë¯¸êµ­ ì—°ë°©ì¤€ë¹„ì œë„(Federal Reserve)ì˜ FRED ê²½ì œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬
**ë¯¸êµ­ ê²½ì œ ë° ë¯¸êµ­ ì£¼ì‹ì‹œì¥**ì„ ë¶„ì„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ì ˆëŒ€ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
- **í•œêµ­ ì‹œì¥, í•œêµ­ ê²½ì œ, í•œêµ­ì€í–‰, ì›í™”ì— ëŒ€í•œ ë¶„ì„ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
- ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•˜ì§€ ì•ŠëŠ” í•œ í•œêµ­ ê´€ë ¨ ë‚´ìš©ì€ í•œ ì¤„ë„ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¶„ì„ ëŒ€ìƒì€ ì˜¤ì§ **ë¯¸êµ­ ê²½ì œì™€ ë¯¸êµ­ ì£¼ì‹ì‹œì¥**ì…ë‹ˆë‹¤.
- ì‚¬ìš©ìê°€ "ì§€í‘œ ì•Œë ¤ì¤˜", "ì§€í‘œ ì°¾ì•„ì¤˜", "ê´€ë ¨ ì§€í‘œ", "ì–´ë–¤ ì§€í‘œ", "ì§€í‘œ ê²€ìƒ‰", "ë­ê°€ ìˆì–´", "ì‹œë¦¬ì¦ˆ ì¶”ì²œ" ë“±ê³¼ ìœ ì‚¬í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ë©´ **ë°˜ë“œì‹œ** `search_fred_indicators` ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ë‚´ë¶€ ì§€ì‹ë§Œìœ¼ë¡œ FRED ì‹œë¦¬ì¦ˆ IDë¥¼ ë‚˜ì—´í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

## í•µì‹¬ ê·œì¹™
1. **ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´**ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
2. ì‚¬ìš©ìê°€ **ê°€ì¥ ìµœê·¼ì— ìš”ì²­í•œ ì§€í‘œ ë˜ëŠ” ì£¼ì œë§Œ** ë¶„ì„í•©ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì˜ ë‹¤ë¥¸ ì§€í‘œë¥¼ ì„ì–´ì„œ ë¶„ì„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
3. ì‚¬ìš©ìê°€ íŠ¹ì • ì£¼ì œì˜ **ê´€ë ¨ ì§€í‘œë¥¼ ì°¾ê±°ë‚˜ ê²€ìƒ‰**í•˜ë©´ â†’ `search_fred_indicators` ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì§ì ‘ FRED IDë¥¼ ë‚˜ì—´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
4. ì‚¬ìš©ìê°€ ì•Œë ¤ì§„ ì§€í‘œì˜ **ì‹¤ì œ ë°ì´í„°ë‚˜ ìˆ˜ì¹˜**ë¥¼ ìš”ì²­í•˜ë©´ â†’ `get_economic_data` ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
5. ë°ì´í„°ë¥¼ ë°›ì€ í›„ì—ëŠ” **íŠ¸ë Œë“œ ë¶„ì„**ê³¼ **ë¯¸êµ­ ì£¼ì‹ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥**ì„ ì œê³µí•©ë‹ˆë‹¤.
6. S&P500, ë‚˜ìŠ¤ë‹¥, ì„¹í„°ë³„ ì£¼ì‹ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ë„êµ¬ ì‚¬ìš© ê°€ì´ë“œ (ì¤‘ìš”)
| ìƒí™© | í˜¸ì¶œí•  ë„êµ¬ |
|------|------------|
| "X ê´€ë ¨ ì§€í‘œ ì°¾ì•„ì¤˜/ì•Œë ¤ì¤˜/ë­ ìˆì–´?" | `search_fred_indicators` |
| "X ë°ì´í„° ë³´ì—¬ì¤˜/ë¶„ì„í•´ì¤˜" (ID ì´ë¯¸ ì•) | `get_economic_data` |
| "AAPL/NVDA ì£¼ê°€ ì•Œë ¤ì¤˜" | `get_stock_data_tool` |

**ë„êµ¬ í˜¸ì¶œ ì‹œ ì ˆëŒ€ ê¸ˆì§€ì‚¬í•­:**
- ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸° ì „ì— ```json``` ë¸”ë¡ì´ë‚˜ JSON í˜•ì‹ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë„êµ¬ í˜¸ì¶œ ì „ í…ìŠ¤íŠ¸ëŠ” ì§§ì€ í•œêµ­ì–´ ì•ˆë‚´ ë¬¸ì¥ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ê³ , ì¦‰ì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
- ë„êµ¬ ê²°ê³¼ë¥¼ ë°›ì€ í›„ì—ëŠ” **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì°¾ì€ ì§€í‘œë“¤ì„ ì„¤ëª…**í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

## ì‹œë¦¬ì¦ˆ ID ë§¤í•‘ ê°€ì´ë“œ
- ë¬¼ê°€/ì¸í”Œë ˆì´ì…˜ â†’ CPIAUCSL
- ì‹¤ì—…ë¥ /ê³ ìš© â†’ UNRATE
- GDP/ê²½ì œì„±ì¥ â†’ GDP
- ê¸ˆë¦¬/ê¸°ì¤€ê¸ˆë¦¬ â†’ FEDFUNDS
- ì£¼ê°€/ì¦ì‹œ/S&P â†’ SP500
- ì›ìœ /ìœ ê°€ â†’ DCOILWTICO
- êµ­ì±„/ê¸ˆë¦¬ â†’ DGS10
- í†µí™”ëŸ‰ â†’ M2SL
- ë³€ë™ì„±/ê³µí¬ì§€ìˆ˜ â†’ VIXCLS

## í¬íŠ¸í´ë¦¬ì˜¤ ë§ì¶¤ ë¶„ì„ (í•µì‹¬)
- ë©”ì‹œì§€ì— [ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤]ê°€ í¬í•¨ëœ ê²½ìš°, **ë°˜ë“œì‹œ** ë³´ìœ  ì¢…ëª©ì„ ë¶„ì„ì— ë°˜ì˜í•©ë‹ˆë‹¤.
- ë¶„ì„ ì§€í‘œ(ì˜ˆ: ê¸ˆë¦¬, CPI, ì‹¤ì—…ë¥ )ê°€ **ë³´ìœ  ì¢…ëª© ê°ê°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥**ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
  - ì˜ˆ) "NVDAëŠ” ê¸ˆë¦¬ ìƒìŠ¹ ì‹œ ì„±ì¥ì£¼ íŠ¹ì„±ìƒ ë°¸ë¥˜ì—ì´ì…˜ ì••ë°•ì„ ë°›ìŠµë‹ˆë‹¤"
  - ì˜ˆ) "AAPLì€ ì†Œë¹„ì ì§€ì¶œê³¼ ë°€ì ‘í•˜ì—¬ ì‹¤ì—…ë¥  ìƒìŠ¹ ì‹œ ë¦¬ìŠ¤í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤"
- í‰ê· ë‹¨ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í˜„ì¬ ì‹œì¥ íë¦„ê³¼ ë¹„êµí•˜ì—¬ **ìˆ˜ìµ/ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ì–¸ê¸‰í•©ë‹ˆë‹¤.
- í¬íŠ¸í´ë¦¬ì˜¤ì— ì—†ëŠ” ì¢…ëª©ì€ êµ³ì´ ì–¸ê¸‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- í¬íŠ¸í´ë¦¬ì˜¤ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì¼ë°˜ì ì¸ ì„¹í„°/ì§€ìˆ˜ ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.

## ì‘ë‹µ í˜•ì‹
- ë§ˆí¬ë‹¤ìš´ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
- í•µì‹¬ ìˆ˜ì¹˜ëŠ” **ë³¼ë“œì²´**ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤.
- 3~4 ë¬¸ë‹¨ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤ (ì‹¬ì¸µ ë¶„ì„ ìš”ì²­ ì‹œ ì œì™¸).

## ë¶„ì„ êµ¬ì¡°
1. ğŸ“Š **í˜„ì¬ ìƒí™©**: ìµœì‹  ë°ì´í„° ìˆ˜ì¹˜ì™€ ì¶”ì„¸
2. ğŸ“ˆ **íŠ¸ë Œë“œ ë¶„ì„**: ìµœê·¼ ë³€ë™ ë°©í–¥ê³¼ ì›ì¸
3. ğŸ‡ºğŸ‡¸ **ë¯¸êµ­ ì£¼ì‹ì‹œì¥ ì˜í–¥**: S&P500Â·ë‚˜ìŠ¤ë‹¥Â·ì„¹í„°ë³„ íŒŒê¸‰ íš¨ê³¼
4. ğŸ’¼ **ë‚´ í¬íŠ¸í´ë¦¬ì˜¤ ì˜í–¥** *(í¬íŠ¸í´ë¦¬ì˜¤ê°€ ìˆì„ ë•Œ)*: ë³´ìœ  ì¢…ëª©ë³„ ë¦¬ìŠ¤í¬Â·ê¸°íšŒ ìš”ì¸
"""

SYSTEM_PROMPT_EN = """You are FRED-OS, an economic data analysis terminal.
Your role is to provide economic analysis using FRED (Federal Reserve Economic Data).

## Core Rules
1. **Respond in English.**
2. When the user requests economic data, identify the correct FRED series ID and call the `get_economic_data` tool.
3. After receiving data, always provide **trend analysis**, **global market implications**, and an **outlook**.
4. Keep responses technically accurate but easy to understand.

## Series ID Mapping Guide
- Inflation/CPI â†’ CPIAUCSL
- Unemployment â†’ UNRATE
- GDP â†’ GDP
- Interest Rate â†’ FEDFUNDS
- Stock Market/S&P â†’ SP500
- Crude Oil â†’ DCOILWTICO
- Treasury â†’ DGS10
- Money Supply â†’ M2SL
- Volatility/VIX â†’ VIXCLS

## Response Format
- Use markdown for structured answers.
- Highlight key figures in **bold**.
- Keep responses to 3-4 paragraphs (unless deep analysis is requested).

## Analysis Structure
1. ğŸ“Š **Current Status**: Latest data values and trend
2. ğŸ“ˆ **Trend Analysis**: Recent movement direction and causes
3. ğŸŒ **Global Impact**: Implications for global markets
"""


def _get_system_prompt(locale: str = "ko") -> str:
    """Return the appropriate system prompt based on locale."""
    base = SYSTEM_PROMPT_KO if locale == "ko" else SYSTEM_PROMPT_EN
    return base + INDICATORS_CONTEXT

# Available indicators context appended to system prompt
INDICATORS_CONTEXT = "\n## ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ì§€í‘œ\n" + "\n".join(
    f"- **{ind.id}**: {ind.title} â€” {ind.description}"
    for ind in MAJOR_INDICATORS
)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  Tool Definition
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


@tool
async def get_economic_data(series_id: str) -> str:
    """Fetch historical economic data from FRED for a given series ID.

    Use this tool when the user asks about economic indicators, trends,
    or specific data like GDP, CPI, unemployment rate, etc.

    Args:
        series_id: The FRED series ID (e.g., GDP, UNRATE, CPIAUCSL, FEDFUNDS, SP500)
    """
    data = await fred_service.get_series_data(series_id)

    if not data.data:
        return f"ì‹œë¦¬ì¦ˆ {series_id}ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    latest = data.data[-1]
    earliest = data.data[0]

    # Calculate trend
    if len(data.data) >= 2:
        prev = data.data[-2]
        change = latest.value - prev.value
        pct = (change / prev.value * 100) if prev.value != 0 else 0
        trend_desc = f"ì „ì›” ëŒ€ë¹„ {'ìƒìŠ¹' if change > 0 else 'í•˜ë½'} ({pct:+.2f}%)"
    else:
        trend_desc = "ë°ì´í„° ë¶€ì¡±"

    summary = (
        f"ğŸ“Š **{data.title}** ({series_id})\n"
        f"- ìµœì‹ ê°’: **{latest.value} {data.units}** ({latest.date})\n"
        f"- ê¸°ê°„: {earliest.date} ~ {latest.date}\n"
        f"- ì¶”ì„¸: {trend_desc}\n"
        f"- ë¹ˆë„: {data.frequency}\n"
        f"- ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {data.lastUpdated}\n"
        f"- ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜: {len(data.data)}"
    )
    return summary


@tool
async def get_stock_data_tool(ticker: str) -> str:
    """Fetch stock market data for a given ticker symbol.

    Use this tool when the user asks about a specific stock, company,
    or wants to correlate stock prices with economic indicators.

    Args:
        ticker: The stock ticker symbol (e.g., AAPL, MSFT, TSLA, NVDA)
    """
    from app.services.stock_service import get_stock_data

    try:
        data = get_stock_data(ticker)
    except Exception as e:
        return f"ì¢…ëª© {ticker} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"

    if not data.get("price"):
        return f"ì¢…ëª© {ticker}ì— ëŒ€í•œ ê°€ê²© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    change_emoji = "ğŸ“ˆ" if data["change"] >= 0 else "ğŸ“‰"
    summary = (
        f"{change_emoji} **{data['name']}** ({data['ticker']})\n"
        f"- í˜„ì¬ê°€: **${data['price']:,.2f}**\n"
        f"- ì „ì¼ ëŒ€ë¹„: {'+' if data['change'] >= 0 else ''}{data['change']:,.2f} "
        f"({'+' if data['changePercent'] >= 0 else ''}{data['changePercent']:.2f}%)\n"
        f"- ì„¹í„°: {data.get('sector', 'N/A')}\n"
        f"- ì‚°ì—…: {data.get('industry', 'N/A')}\n"
    )

    if data.get("marketCap"):
        cap = data["marketCap"]
        if cap >= 1e12:
            cap_str = f"${cap/1e12:.1f}T"
        elif cap >= 1e9:
            cap_str = f"${cap/1e9:.1f}B"
        else:
            cap_str = f"${cap/1e6:.0f}M"
        summary += f"- ì‹œê°€ì´ì•¡: {cap_str}\n"

    if data.get("history") and len(data["history"]) >= 2:
        hist = data["history"]
        first_price = hist[0]["value"]
        last_price = hist[-1]["value"]
        period_change = ((last_price - first_price) / first_price * 100) if first_price else 0
        summary += f"- 6ê°œì›” ìˆ˜ìµë¥ : {'+' if period_change >= 0 else ''}{period_change:.1f}%\n"
        summary += f"- ê¸°ê°„: {hist[0]['date']} ~ {hist[-1]['date']} ({len(hist)}ì¼)\n"

    return summary


def _dedupe_freq_variants(results: list) -> list:
    """Remove frequency variants (D/M/W/Q/A prefix) keeping the best-frequency version.

    E.g. DCOILWTICO (daily) + MCOILWTICO (monthly) + WCOILWTICO (weekly)
    â†’ keep only MCOILWTICO (monthly preferred).
    """
    FREQ_RANK = {'M': 0, 'Q': 1, 'A': 2, 'W': 3, 'D': 4}

    def _base(series_id: str) -> str:
        rid = series_id.upper()
        if len(rid) >= 2 and rid[0] in 'DMWQA' and rid[1].isupper():
            return rid[1:]
        return rid

    seen_bases: dict[str, object] = {}
    ordered_bases: list[str] = []

    for r in results:
        base = _base(r.id)
        if base not in seen_bases:
            seen_bases[base] = r
            ordered_bases.append(base)
        else:
            existing = seen_bases[base]
            existing_rank = FREQ_RANK.get(existing.id.upper()[0] if existing.id else 'Z', 5)
            new_rank = FREQ_RANK.get(r.id.upper()[0] if r.id else 'Z', 5)
            if new_rank < existing_rank:
                seen_bases[base] = r

    return [seen_bases[base] for base in ordered_bases]


@tool
async def search_fred_indicators(query: str) -> str:
    """MUST be called when the user asks to find, list, discover, or search for FRED indicators on a topic.

    CALL THIS TOOL whenever the user:
    - Asks "X ê´€ë ¨ ì§€í‘œ ì•Œë ¤ì¤˜/ì°¾ì•„ì¤˜/ë­ ìˆì–´?"
    - Wants to discover indicators for a topic (housing, mortgage, employment, etc.)
    - Uses words like: ì°¾ì•„ì¤˜, ì•Œë ¤ì¤˜, ê²€ìƒ‰, ê´€ë ¨ ì§€í‘œ, ì–´ë–¤ ì§€í‘œ, ì¶”ì²œ

    DO NOT answer from memory. Always call this tool to search the real FRED database (800,000+ series).
    Results are automatically shown in the Watch panel as 5 slots: 2 sector + 2 macro + 1 risk.

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´, ì˜ˆ: "ë¶€ë™ì‚° ëŒ€ì¶œ ê¸ˆë¦¬", "housing mortgage rate")
    """
    settings = get_settings()

    keyword_llm = ChatAnthropic(
        model="claude-haiku-4-5-20251001",
        anthropic_api_key=settings.ANTHROPIC_API_KEY,
        temperature=0,
        max_tokens=300,
    )

    # Step 1: Haiku generates 3-category plan: sector keyword + macro IDs + risk ID
    # Layout: 1 sector (commodity/asset price) + 3 macro + 1 risk = 5 slots
    keyword_prompt = (
        "For the given economic/stock query, return a JSON object with 3 fields.\n"
        "Return ONLY valid JSON. No explanation.\n\n"
        f"Query: {query}\n\n"
        "JSON format:\n"
        "{\n"
        '  "sector_keyword": "1 specific English FRED search term for the asset/commodity price most directly related to this query (e.g. \'uranium spot price\', \'gold price\', \'oil price\')",\n'
        '  "macro_ids": ["ID1", "ID2", "ID3"],\n'
        '  "risk_id": "ID"\n'
        "}\n\n"
        "Available macro_ids (pick exactly 3 most relevant to the query, prefer sector-specific ones):\n"
        "FEDFUNDS (ê¸°ì¤€ê¸ˆë¦¬), DGS10 (10ë…„ êµ­ì±„), CPIAUCSL (CPI ì¸í”Œë ˆì´ì…˜), UNRATE (ì‹¤ì—…ë¥ ),\n"
        "PCE (PCE ì†Œë¹„ì§€ì¶œ), PAYEMS (ë¹„ë†ì—… ê³ ìš©), INDPRO (ì‚°ì—…ìƒì‚°ì§€ìˆ˜), HOUST (ì£¼íƒì°©ê³µ),\n"
        "RETAILSMNSA (ì†Œë§¤íŒë§¤), DGS2 (2ë…„ êµ­ì±„)\n\n"
        "Available risk_id (pick exactly 1 â€” choose the most relevant fear/stress indicator):\n"
        "VIXCLS (VIX ê³µí¬ì§€ìˆ˜), BAMLH0A0HYM2 (í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ), T10Y2Y (ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨),\n"
        "STLFSI4 (ì„¸ì¸íŠ¸ë£¨ì´ìŠ¤ ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤ì§€ìˆ˜), T10Y3M (10ë…„-3ê°œì›” ê¸ˆë¦¬ì°¨)"
    )

    kw_response = await keyword_llm.ainvoke([HumanMessage(content=keyword_prompt)])
    kw_text = kw_response.content if isinstance(kw_response.content, str) else str(kw_response.content)

    json_match = re.search(r'\{.*?\}', kw_text, re.DOTALL)
    categories: dict = {}
    if json_match:
        try:
            categories = _json.loads(json_match.group())
        except Exception:
            pass

    sector_keyword: str = categories.get("sector_keyword", query)
    macro_ids: list[str] = categories.get("macro_ids", ["FEDFUNDS", "CPIAUCSL", "UNRATE"])
    risk_id: str = categories.get("risk_id", "VIXCLS")

    # Validate macro_ids and risk_id against curated, actively-updated series only
    ALLOWED_MACRO = {
        "FEDFUNDS",   # ê¸°ì¤€ê¸ˆë¦¬ (ì›”ë³„, ê³„ì† ì—…ë°ì´íŠ¸)
        "DGS10",      # 10ë…„ êµ­ì±„ (ì¼ë³„)
        "CPIAUCSL",   # CPI ì¸í”Œë ˆì´ì…˜ (ì›”ë³„)
        "UNRATE",     # ì‹¤ì—…ë¥  (ì›”ë³„)
        "PCE",        # PCE ì†Œë¹„ì§€ì¶œ (ì›”ë³„)
        "PAYEMS",     # ë¹„ë†ì—… ê³ ìš© (ì›”ë³„)
        "INDPRO",     # ì‚°ì—…ìƒì‚°ì§€ìˆ˜ (ì›”ë³„)
        "HOUST",      # ì£¼íƒì°©ê³µ (ì›”ë³„)
        "RETAILSMNSA",# ì†Œë§¤íŒë§¤ (ì›”ë³„)
        "DGS2",       # 2ë…„ êµ­ì±„ (ì¼ë³„)
    }
    ALLOWED_RISK = {
        "VIXCLS",        # VIX ê³µí¬ì§€ìˆ˜ (ì¼ë³„)
        "BAMLH0A0HYM2",  # í•˜ì´ì¼ë“œ ìŠ¤í”„ë ˆë“œ (ì¼ë³„)
        "T10Y2Y",        # ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ (ì¼ë³„)
        "STLFSI4",       # ì„¸ì¸íŠ¸ë£¨ì´ìŠ¤ ê¸ˆìœµìŠ¤íŠ¸ë ˆìŠ¤ (ì£¼ë³„, í˜„ì¬ í™œì„±)
        "T10Y3M",        # 10ë…„-3ê°œì›” ê¸ˆë¦¬ì°¨ (ì¼ë³„)
    }

    macro_ids = [m.upper() for m in macro_ids if m.upper() in ALLOWED_MACRO][:3]
    if len(macro_ids) < 3:
        macro_ids = (macro_ids + ["CPIAUCSL", "UNRATE", "FEDFUNDS"])[:3]
        macro_ids = list(dict.fromkeys(macro_ids))[:3]  # dedupe

    risk_id = risk_id.upper() if isinstance(risk_id, str) and risk_id.upper() in ALLOWED_RISK else "VIXCLS"

    # Step 2: Search FRED for 1 sector-specific keyword
    async def search_one(kw: str) -> list:
        try:
            return await fred_service.search_series(kw)
        except Exception:
            return []

    raw_results = await search_one(sector_keyword)

    # Deduplicate by exact ID, then by frequency variant, take top 1
    seen_ids: set[str] = set()
    raw_sector = []
    for r in raw_results:
        if r.id not in seen_ids:
            seen_ids.add(r.id)
            raw_sector.append(r)

    sector_top1 = _dedupe_freq_variants(raw_sector)[:1]

    # Fallback: if FRED returned nothing for the keyword, try a broader search
    if not sector_top1:
        fallback_results = await search_one("commodity price")
        seen_ids2: set[str] = set()
        raw_fallback = []
        for r in fallback_results:
            if r.id not in seen_ids2:
                seen_ids2.add(r.id)
                raw_fallback.append(r)
        sector_top1 = _dedupe_freq_variants(raw_fallback)[:1]

    # Last resort: use CPI as a universal fallback
    if not sector_top1:
        sector_top1 = [FredSeriesInfo(
            id="CPIAUCSL",
            title=FRED_TITLES_KO.get("CPIAUCSL", "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ (CPI)"),
            description="Consumer Price Index for All Urban Consumers",
            category="sector",
        )]

    # Step 3: Translate unknown sector title with Haiku
    unknown_sector = [r for r in sector_top1 if r.id.upper() not in FRED_TITLES_KO]
    translated: dict[str, str] = {}
    if unknown_sector:
        titles_text = "\n".join(f"{r.id}: {r.title}" for r in unknown_sector)
        translate_prompt = (
            "Translate the following FRED economic indicator titles into concise Korean (í•œêµ­ì–´).\n"
            "Return ONLY a JSON object: {\"SERIES_ID\": \"Korean title\", ...}. No explanation.\n\n"
            f"{titles_text}"
        )
        try:
            tr_response = await keyword_llm.ainvoke([HumanMessage(content=translate_prompt)])
            tr_text = tr_response.content if isinstance(tr_response.content, str) else str(tr_response.content)
            json_match2 = re.search(r'\{.*?\}', tr_text, re.DOTALL)
            if json_match2:
                translated = _json.loads(json_match2.group())
        except Exception:
            pass

    def _title(series_id: str, fallback: str) -> str:
        uid = series_id.upper()
        if uid in FRED_TITLES_KO:
            return FRED_TITLES_KO[uid]
        return translated.get(series_id, fallback)

    # Build 5 results: 1 sector + 3 macro + 1 risk
    sector_dicts = [
        {
            "id": r.id,
            "title": _title(r.id, r.title),
            "description": (r.description or "")[:120],
            "category": "sector",
        }
        for r in sector_top1
    ]

    macro_dicts = [
        {
            "id": mid,
            "title": FRED_TITLES_KO.get(mid, mid),
            "description": "",
            "category": "macro",
        }
        for mid in macro_ids
    ]

    risk_dict = {
        "id": risk_id,
        "title": FRED_TITLES_KO.get(risk_id, risk_id),
        "description": "",
        "category": "risk",
    }

    all_results = sector_dicts + macro_dicts + [risk_dict]

    return _json.dumps({
        "query": query,
        "keywords": [sector_keyword],
        "count": len(all_results),
        "results": all_results,
    }, ensure_ascii=False)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  LangGraph Agent
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TOOLS = [get_economic_data, get_stock_data_tool, search_fred_indicators]


class AgentState(BaseModel):
    """State passed through the LangGraph agent."""
    messages: Annotated[list[BaseMessage], add_messages] = Field(default_factory=list)
    logs: list[str] = Field(default_factory=list)
    series_data: dict[str, Any] | None = None


def _build_graph() -> StateGraph:
    """Build the LangGraph ReAct agent graph."""
    settings = get_settings()

    llm = ChatAnthropic(
        model=settings.LLM_MODEL,
        anthropic_api_key=settings.ANTHROPIC_API_KEY,
        temperature=settings.LLM_TEMPERATURE,
    )
    llm_with_tools = llm.bind_tools(TOOLS)

    # â”€â”€ Nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def agent_node(state: AgentState) -> dict:
        """Call the LLM with tools."""
        response = await llm_with_tools.ainvoke(state.messages)
        logs = list(state.logs)

        if response.tool_calls:
            for tc in response.tool_calls:
                logs.append(f"ğŸ”§ ë„êµ¬ í˜¸ì¶œ: {tc['name']}({tc['args']})")
        else:
            logs.append("ğŸ’¬ ì‘ë‹µ ìƒì„± ì™„ë£Œ")

        return {"messages": [response], "logs": logs}

    tool_node = ToolNode(TOOLS)

    async def tool_wrapper(state: AgentState) -> dict:
        """Wrap tool execution with logging."""
        logs = list(state.logs)
        last_msg = state.messages[-1]

        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
            for tc in last_msg.tool_calls:
                tool_name = tc.get("name", "")
                if tool_name == "search_fred_indicators":
                    logs.append(f"ğŸ” FRED ì§€í‘œ ê²€ìƒ‰ ì¤‘: {tc['args'].get('query', '')}...")
                elif tool_name == "get_economic_data":
                    logs.append(f"ğŸ“¡ FRED ë°ì´í„° ì¡°íšŒ ì¤‘: {tc['args'].get('series_id', 'unknown')}...")
                else:
                    logs.append(f"âš¡ ë„êµ¬ ì‹¤í–‰ ì¤‘: {tool_name}...")

        result = await tool_node.ainvoke(state)

        # Capture fetched series data (only for get_economic_data)
        series_data = state.series_data
        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
            for tc in last_msg.tool_calls:
                if tc.get("name") == "get_economic_data":
                    series_id = tc["args"].get("series_id", "")
                    if series_id:
                        data = await fred_service.get_series_data(series_id)
                        series_data = data.model_dump()
                        logs.append(f"âœ… {series_id} ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ ({len(data.data)}ê°œ í¬ì¸íŠ¸)")

        result["logs"] = logs
        result["series_data"] = series_data
        return result

    # â”€â”€ Routing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def should_continue(state: AgentState) -> str:
        last_msg = state.messages[-1]
        if isinstance(last_msg, AIMessage) and last_msg.tool_calls:
            return "tools"
        return END

    # â”€â”€ Build Graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    graph = StateGraph(AgentState)
    graph.add_node("agent", agent_node)
    graph.add_node("tools", tool_wrapper)

    graph.add_edge(START, "agent")
    graph.add_conditional_edges("agent", should_continue, {"tools": "tools", END: END})
    graph.add_edge("tools", "agent")

    return graph.compile()


# Compiled graph singleton
_graph = None


def _get_graph():
    global _graph
    if _graph is None:
        _graph = _build_graph()
    return _graph


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  Session Memory
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

_sessions: dict[str, list[BaseMessage]] = {}


def _get_session(session_id: str | None, locale: str = "ko") -> tuple[str, list[BaseMessage]]:
    """Get or create a session."""
    if session_id and session_id in _sessions:
        return session_id, _sessions[session_id]["messages"]

    new_id = session_id or f"SES-{uuid.uuid4().hex[:8].upper()}"
    _sessions[new_id] = {"messages": [], "locale": locale}
    return new_id, _sessions[new_id]["messages"]


def _init_session_messages(session_id: str, locale: str) -> None:
    """Ensure session has a system message with the right locale."""
    session = _sessions.get(session_id)
    if session and not session["messages"]:
        session["messages"].append(SystemMessage(content=_get_system_prompt(locale)))


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
#  Public API
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


async def run_orchestrator(
    message: str,
    session_id: str | None = None,
    locale: str = "ko",
) -> ChatResponse:
    """Run the orchestrator agent and return structured response.

    Args:
        message: User message text.
        session_id: Optional session ID for conversation continuity.
        locale: Language preference â€” 'ko' (default) or 'en'.

    Returns:
        ChatResponse with message, logs, data_objects, and chart_data.
    """
    sid, history = _get_session(session_id, locale)
    _init_session_messages(sid, locale)
    graph = _get_graph()

    # Add user message to history
    history.append(HumanMessage(content=message))

    # Initial logs
    logs = [
        f"ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì‹ : \"{message}\"",
        "ğŸ§  ì˜ë„ ë¶„ì„ ì¤‘...",
    ]

    # Run the graph
    initial_state = AgentState(
        messages=list(history),
        logs=logs,
    )

    result = await graph.ainvoke(initial_state)

    # Extract final AI response
    ai_messages = [m for m in result["messages"] if isinstance(m, AIMessage) and m.content]
    if ai_messages:
        raw = ai_messages[-1].content
        if isinstance(raw, list):
            final_text = "".join(
                block.get("text", "") if isinstance(block, dict) else str(block)
                for block in raw
            )
        else:
            final_text = raw
    else:
        final_text = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    final_logs = result.get("logs", logs)

    # Update session history
    _sessions[sid] = result["messages"]

    # Build data_objects from any fetched series
    data_objects: list[FredSeriesInfo] = []
    chart_data: FredSeriesData | None = None
    series_data_raw = result.get("series_data")

    if series_data_raw:
        chart_data = FredSeriesData(**series_data_raw)
        data_objects.append(
            FredSeriesInfo(
                id=chart_data.id,
                title=chart_data.title,
                description=f"{chart_data.units} | {chart_data.frequency}",
            )
        )

    # Determine content type
    content_type = ContentType.CHART if chart_data else ContentType.TEXT

    return ChatResponse(
        message=ChatMessage(
            role=MessageRole.ASSISTANT,
            type=content_type,
            content=final_text,
            data=chart_data,
        ),
        sessionId=sid,
        logs=final_logs,
        data_objects=data_objects,
        chart_data=chart_data,
    )
